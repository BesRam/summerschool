name: Local Assistant
version: 1.0.0
schema: v1

models:
  - name: llama3.2:latest
    provider: ollama
    model: llama3.2:latest
    url: http://localhost:11434
    completionOptions:
      temperature: 0.7
      top_p: 0.9

defaultModel: llama3.1

context:
  - provider: code
  - provider: docs
  - provider: diff
  - provider: terminal
  - provider: problems
  - provider: folder
  - provider: codebase